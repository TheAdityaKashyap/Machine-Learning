{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042874d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_ml_pipeline_no_employee.py\n",
    "\n",
    "# ML pipeline for invoice-level sales data with columns:\n",
    "# - INV No\n",
    "# - Date\n",
    "# - Customer Name\n",
    "# - Document Total\n",
    "\n",
    "# This version removes any Sales Employee logic (per user request) and focuses on:\n",
    "# - Data cleaning & validation\n",
    "# - Exploratory aggregation\n",
    "# - Time-series forecasting (monthly) using Prophet if available, otherwise SARIMAX or moving average\n",
    "# - Customer segmentation (RFM + KMeans)\n",
    "# - Churn prediction (simple RFM-based)\n",
    "# - Invoice value prediction using:\n",
    "#     * Linear Regression (LR)\n",
    "#     * Decision Tree Regressor (DT)\n",
    "#     * Random Forest Regressor (RF) as a strong benchmark\n",
    "# - Model comparison and saving results\n",
    "\n",
    "# Usage:\n",
    "#     python sales_ml_pipeline_no_employee.py --input \"C:/path/to/INVOICE_DATA-MLR-DT-LR.xlsx\" --output_dir ./output --date_col Date\n",
    "\n",
    "# Notes:\n",
    "# - Script auto-detects .xlsx/.xls and .csv\n",
    "# - Required packages:\n",
    "#     pandas numpy scikit-learn matplotlib joblib statsmodels prophet (optional)\n",
    "# \"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Optional forecasting libs\n",
    "HAS_PROPHET = False\n",
    "HAS_STATS = False\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    HAS_PROPHET = True\n",
    "except Exception:\n",
    "    try:\n",
    "        from fbprophet import Prophet\n",
    "        HAS_PROPHET = True\n",
    "    except Exception:\n",
    "        HAS_PROPHET = False\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    HAS_STATS = True\n",
    "except Exception:\n",
    "    HAS_STATS = False\n",
    "\n",
    "def read_data(path, date_col='Date'):\n",
    "    path = str(path)\n",
    "    if path.lower().endswith(('.xls', '.xlsx')):\n",
    "        df = pd.read_excel(path)\n",
    "    else:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "    if date_col not in df.columns:\n",
    "        raise ValueError(f\"Date column '{date_col}' not found in input. Columns: {df.columns.tolist()}\")\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "    df = df.rename(columns=lambda x: x.strip())\n",
    "    for c in df.select_dtypes(include='object').columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def basic_clean(df):\n",
    "    # Ensure Document Total numeric\n",
    "    if 'Document Total' not in df.columns:\n",
    "        possible = [c for c in df.columns if 'document' in c.lower() and 'total' in c.lower()]\n",
    "        if possible:\n",
    "            df = df.rename(columns={possible[0]:'Document Total'})\n",
    "        else:\n",
    "            raise ValueError(\"Document Total column not found.\")\n",
    "    df['Document Total'] = pd.to_numeric(df['Document Total'], errors='coerce').fillna(0.0)\n",
    "    if 'INV No' not in df.columns:\n",
    "        df['INV No'] = pd.Series(np.arange(1, len(df)+1)).astype(str)\n",
    "    df['INV No'] = df['INV No'].astype(str)\n",
    "    if 'Customer Name' not in df.columns:\n",
    "        df['Customer Name'] = 'UNKNOWN'\n",
    "    df = df.dropna(subset=['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    df['YearMonth'] = df['Date'].dt.to_period('M').astype(str)\n",
    "    return df\n",
    "\n",
    "def aggregate_time_series(df, freq='M'):\n",
    "    ts = df.set_index('Date').resample(freq)['Document Total'].sum().reset_index()\n",
    "    ts = ts.rename(columns={'Date':'ds', 'Document Total':'y'})\n",
    "    return ts\n",
    "\n",
    "def forecast(ts, periods=12, method_preference='prophet'):\n",
    "    if method_preference == 'prophet' and HAS_PROPHET:\n",
    "        m = Prophet()\n",
    "        m.fit(ts)\n",
    "        future = m.make_future_dataframe(periods=periods, freq='M')\n",
    "        forecast = m.predict(future)\n",
    "        return 'prophet', m, forecast\n",
    "    elif HAS_STATS:\n",
    "        # SARIMAX fallback\n",
    "        ts2 = ts.set_index('ds').asfreq('M')\n",
    "        ts2['y'] = ts2['y'].fillna(0)\n",
    "        try:\n",
    "            model = sm.tsa.statespace.SARIMAX(ts2['y'], order=(1,1,1), seasonal_order=(1,1,1,12), enforce_stationarity=False, enforce_invertibility=False)\n",
    "            res = model.fit(disp=False)\n",
    "            pred = res.get_forecast(steps=periods)\n",
    "            pred_index = pd.date_range(start=ts2.index[-1] + pd.offsets.MonthBegin(1), periods=periods, freq='M')\n",
    "            forecast = pd.DataFrame({'ds': pred_index, 'yhat': pred.predicted_mean.values})\n",
    "            return 'sarimax', res, forecast\n",
    "        except Exception as e:\n",
    "            print(\"SARIMAX failed:\", e)\n",
    "    # naive moving average\n",
    "    ts['ma3'] = ts['y'].rolling(3, min_periods=1).mean()\n",
    "    last = ts['ma3'].iloc[-1]\n",
    "    future_idx = pd.date_range(start=ts['ds'].iloc[-1] + pd.offsets.MonthBegin(1), periods=periods, freq='M')\n",
    "    forecast = pd.DataFrame({'ds': future_idx, 'yhat': np.repeat(last, periods)})\n",
    "    return 'naive', None, forecast\n",
    "\n",
    "def rfm_features(df, snapshot_date=None):\n",
    "    if snapshot_date is None:\n",
    "        snapshot_date = df['Date'].max() + pd.Timedelta(days=1)\n",
    "    rfm = df.groupby('Customer Name').agg({\n",
    "        'Date': lambda x: (snapshot_date - x.max()).days,\n",
    "        'INV No': 'count',\n",
    "        'Document Total': 'sum'\n",
    "    }).rename(columns={'Date':'Recency', 'INV No':'Frequency', 'Document Total':'Monetary'})\n",
    "    rfm = rfm.reset_index()\n",
    "    return rfm\n",
    "\n",
    "def customer_segmentation(rfm, n_clusters=4):\n",
    "    rfm2 = rfm.copy()\n",
    "    rfm2['Monetary'] = np.log1p(rfm2['Monetary'])\n",
    "    X = rfm2[['Recency','Frequency','Monetary']].fillna(0)\n",
    "    from sklearn.cluster import KMeans\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=RANDOM_STATE)\n",
    "    rfm2['Cluster'] = kmeans.fit_predict(X)\n",
    "    return rfm2, kmeans\n",
    "\n",
    "def create_churn_label(df, days_window=90):\n",
    "    last_date = df['Date'].max()\n",
    "    cutoff = last_date - pd.Timedelta(days=days_window)\n",
    "    recent = df[df['Date'] > cutoff]['Customer Name'].unique()\n",
    "    customers = df['Customer Name'].unique()\n",
    "    labels = pd.DataFrame({'Customer Name': customers})\n",
    "    labels['churn'] = (~labels['Customer Name'].isin(recent)).astype(int)\n",
    "    return labels\n",
    "\n",
    "def anomaly_detection(df):\n",
    "    df2 = df.copy()\n",
    "    cust_avg = df.groupby('Customer Name')['Document Total'].mean().rename('cust_mean')\n",
    "    df2 = df2.join(cust_avg, on='Customer Name')\n",
    "    df2['ratio'] = df2['Document Total'] / (df2['cust_mean'] + 1e-6)\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    iso = IsolationForest(contamination=0.01, random_state=RANDOM_STATE)\n",
    "    feats = ['Document Total','ratio']\n",
    "    df2['anomaly'] = iso.fit_predict(df2[feats].fillna(0))\n",
    "    df2['is_anomaly'] = (df2['anomaly'] == -1).astype(int)\n",
    "    return df2[['INV No','Date','Customer Name','Document Total','is_anomaly']]\n",
    "\n",
    "def prepare_regression_features(df):\n",
    "    d = df.copy()\n",
    "    cust_avg = df.groupby('Customer Name')['Document Total'].agg(['mean','count']).rename(columns={'mean':'cust_avg','count':'cust_count'})\n",
    "    d = d.join(cust_avg, on='Customer Name')\n",
    "    d['month'] = d['Date'].dt.month\n",
    "    d['dayofweek'] = d['Date'].dt.dayofweek\n",
    "    d['is_month_start'] = d['Date'].dt.is_month_start.astype(int)\n",
    "    d['is_month_end'] = d['Date'].dt.is_month_end.astype(int)\n",
    "    # Encode Customer Name simple\n",
    "    le = LabelEncoder()\n",
    "    d['Customer_enc'] = le.fit_transform(d['Customer Name'].astype(str))\n",
    "    features = ['cust_avg','cust_count','month','dayofweek','is_month_start','is_month_end','Customer_enc']\n",
    "    X = d[features].fillna(0)\n",
    "    y = d['Document Total']\n",
    "    return X, y, d, le\n",
    "\n",
    "def train_and_compare_models(X, y, outdir):\n",
    "    results = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    # Linear Regression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred_lr = lr.predict(X_test)\n",
    "    results['LR'] = {'model': lr, 'rmse': mean_squared_error(y_test, pred_lr, squared=False), 'r2': r2_score(y_test, pred_lr)}\n",
    "    # Decision Tree with simple grid search\n",
    "    dt = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "    param_grid = {'max_depth':[3,5,7,None], 'min_samples_split':[2,5,10]}\n",
    "    gs = GridSearchCV(dt, param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_dt = gs.best_estimator_\n",
    "    pred_dt = best_dt.predict(X_test)\n",
    "    results['DT'] = {'model': best_dt, 'rmse': mean_squared_error(y_test, pred_dt, squared=False), 'r2': r2_score(y_test, pred_dt)}\n",
    "    # Random Forest benchmark\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred_rf = rf.predict(X_test)\n",
    "    results['RF'] = {'model': rf, 'rmse': mean_squared_error(y_test, pred_rf, squared=False), 'r2': r2_score(y_test, pred_rf)}\n",
    "    # Save metrics to CSV\n",
    "    metrics = []\n",
    "    for name, info in results.items():\n",
    "        metrics.append({'model': name, 'rmse': float(info['rmse']), 'r2': float(info['r2'])})\n",
    "        joblib.dump(info['model'], os.path.join(outdir, f\"model_{name}.joblib\"))\n",
    "    pd.DataFrame(metrics).to_csv(os.path.join(outdir, \"model_comparison_metrics.csv\"), index=False)\n",
    "    return results, X_test, y_test\n",
    "\n",
    "def save_fig(fig, path):\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def main(args):\n",
    "    input_path = args.input\n",
    "    outdir = Path(args.output_dir)\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Reading data...\", input_path)\n",
    "    df = read_data(input_path, date_col=args.date_col)\n",
    "    df = basic_clean(df)\n",
    "    print(f\"Rows: {len(df)}; date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")\n",
    "    # Time series\n",
    "    ts_monthly = aggregate_time_series(df, freq='M')\n",
    "    ts_monthly.to_csv(outdir / \"monthly_timeseries.csv\", index=False)\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.plot(ts_monthly['ds'], ts_monthly['y'], marker='o')\n",
    "    ax.set_title('Monthly Sales (Document Total)')\n",
    "    save_fig(fig, outdir / \"monthly_sales.png\")\n",
    "    # Forecast\n",
    "    method, model_obj, forecast_df = forecast(ts_monthly, periods=args.forecast_periods, method_preference='prophet')\n",
    "    if forecast_df is not None:\n",
    "        if 'yhat' in forecast_df.columns:\n",
    "            forecast_df.to_csv(outdir / f\"{method}_forecast.csv\", index=False)\n",
    "        else:\n",
    "            forecast_df.to_csv(outdir / f\"{method}_forecast.csv\", index=False)\n",
    "    # RFM & segmentation\n",
    "    rfm = rfm_features(df)\n",
    "    rfm.to_csv(outdir / \"rfm.csv\", index=False)\n",
    "    rfm2, kmeans = customer_segmentation(rfm, n_clusters=args.n_clusters)\n",
    "    rfm2.to_csv(outdir / \"rfm_segmented.csv\", index=False)\n",
    "    # Churn labels\n",
    "    labels = create_churn_label(df, days_window=args.churn_days_window)\n",
    "    labels.to_csv(outdir / \"churn_labels.csv\", index=False)\n",
    "    # Anomalies\n",
    "    anomalies = anomaly_detection(df)\n",
    "    anomalies.to_csv(outdir / \"anomalies.csv\", index=False)\n",
    "    # Regression models (LR, DT, RF)\n",
    "    X, y, df_feats, cust_le = prepare_regression_features(df)\n",
    "    results, X_test, y_test = train_and_compare_models(X, y, outdir)\n",
    "    # Save sample predictions\n",
    "    best_model_name = min(results.keys(), key=lambda k: results[k]['rmse'])\n",
    "    best_model = results[best_model_name]['model']\n",
    "    df_feats['predicted_invoice_value_'+best_model_name] = best_model.predict(X)\n",
    "    df_feats[['INV No','Date','Customer Name','Document Total','predicted_invoice_value_'+best_model_name]].to_csv(outdir / \"invoice_predictions.csv\", index=False)\n",
    "    # Save encoders and kmeans\n",
    "    joblib.dump(cust_le, outdir / \"customer_labelencoder.joblib\")\n",
    "    joblib.dump(kmeans, outdir / \"customer_kmeans.joblib\")\n",
    "    # Report\n",
    "    report = {\n",
    "        'rows': int(len(df)),\n",
    "        'date_start': str(df['Date'].min().date()),\n",
    "        'date_end': str(df['Date'].max().date()),\n",
    "        'total_revenue': float(df['Document Total'].sum()),\n",
    "        'best_model': best_model_name,\n",
    "        'model_metrics': {k:{'rmse':float(v['rmse']), 'r2':float(v['r2'])} for k,v in results.items()}\n",
    "    }\n",
    "    with open(outdir / \"report.json\", 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    print(\"All outputs saved to\", outdir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"Sales ML pipeline (no employee fields)\")\n",
    "    parser.add_argument('--input', required=True, help='Path to Excel (.xlsx/.xls) or CSV file')\n",
    "    parser.add_argument('--output_dir', default='./output', help='Directory to save outputs')\n",
    "    parser.add_argument('--date_col', default='Date', help='Name of the date column')\n",
    "    parser.add_argument('--forecast_periods', type=int, default=12, help='Months to forecast')\n",
    "    parser.add_argument('--n_clusters', type=int, default=4, help='Number of customer clusters')\n",
    "    parser.add_argument('--churn_days_window', type=int, default=90, help='Days window for churn labeling')\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n",
    "# # write to file\n",
    "# output_path = \"/mnt/data/sales_ml_pipeline_no_employee.py\"\n",
    "# with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(script_content)\n",
    "\n",
    "# print(f\"Script written to {output_path}\")\n",
    "# print(\"Download: sandbox:\" + output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07884a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
